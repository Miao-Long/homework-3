{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "\n",
    "## Name: Christopher Myau\n",
    "\n",
    "## GitHub Username: Miao-Long\n",
    "\n",
    "## USC ID: 7766-9561-85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Time Series Classification Part 1: Feature Creation/Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the AReM Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../AReM/\"\n",
    "\n",
    "\n",
    "def custom_tt_split(directory, directory_name, count):\n",
    "    ret_list1, ret_list2 = [], []\n",
    "    c = 0\n",
    "    for filename in os.listdir(directory + directory_name):\n",
    "        if \"csv\" in filename:\n",
    "            if c < count:\n",
    "                ret_list1.append(pd.read_csv(directory + directory_name + filename, comment=\"#\", header=None))\n",
    "            else:\n",
    "                ret_list2.append(pd.read_csv(directory + directory_name + filename, comment=\"#\", header=None))\n",
    "            c += 1\n",
    "    return [ret_list1, ret_list2]\n",
    "\n",
    "[bending_test, bending_train] = custom_tt_split(directory, \"bending1/\", 2)\n",
    "[bending_test2, bending_train2] = custom_tt_split(directory, \"bending2/\", 2)\n",
    "[bending_test, bending_train] = [bending_test + bending_test2, bending_train + bending_train2]\n",
    "[cycling_test, cycling_train] = custom_tt_split(directory, \"cycling/\", 3)\n",
    "[lying_test, lying_train] = custom_tt_split(directory, \"lying/\", 3)\n",
    "[sitting_test, sitting_train] = custom_tt_split(directory, \"sitting/\", 3)\n",
    "[standing_test, standing_train] = custom_tt_split(directory, \"standing/\", 3)\n",
    "[walking_test, walking_train] = custom_tt_split(directory, \"walking/\", 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Test and Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [bending_test, cycling_test, lying_test, sitting_test, standing_test, walking_test]\n",
    "train_data = [bending_train, cycling_train, lying_train, sitting_train, standing_train, walking_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### i. Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean - the average or expected value of a time series at a certain time. Trimmed mean or median can also be used.\n",
    "\n",
    "Variance - the dispersion of values around the mean.\n",
    "\n",
    "Range - the difference between the largest and smallest values.\n",
    "\n",
    "PDF of Amplitutde - the probability distribution function of the amplitudes of a time series.\n",
    "\n",
    "Skewness - The symmetry of the PDF of amplitutde.\n",
    "\n",
    "Kurtosis - The \"sharpness\" of the peak of the PDF. A kurtosis of 3 is approximately equal to normal distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ii. Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO use https://pypi.org/project/bootstrapped/ instead\n",
    "\n",
    "def metrics_extraction(t_data, columns, sortedIndex):\n",
    "    metrics_df = pd.DataFrame({}, columns = columns)\n",
    "    for data in t_data:\n",
    "        for df in data:\n",
    "            instance_metrics = []\n",
    "            for i in range(1, 7): \n",
    "                metrics = list(df[i].describe())\n",
    "                metrics = [metrics[m] for m in range(0, len(metrics)) if m not in [0, 5]]\n",
    "                metrics.insert(3, df[i].median())\n",
    "                \n",
    "                # goal: min, max, mean, median, std, 25, 75\n",
    "                #      mean, std, min, median, 25, 75, max\n",
    "                metrics = [metrics[i] for i in sortedIndex]\n",
    "                instance_metrics = instance_metrics + metrics\n",
    "            metrics_df.loc[len(metrics_df)] = instance_metrics\n",
    "    return metrics_df\n",
    "\n",
    "\n",
    "metric_names, metric_offset = [\"avg_rss12\",\"var_rss12\",\"avg_rss13\",\"var_rss13\",\"avg_rss23\",\"var_rss23\"], 1\n",
    "column_names = [\"min\", \"max\", \"mean\", \"median\", \"std\", \"first_quartile\", \"third_quartile\"]\n",
    "sortedIndex = [2, 6, 0, 3, 1, 4, 5]\n",
    "column_names_expanded = [f\"{c}{i}\" for i in range(metric_offset, len(metric_names) + metric_offset) for c in column_names ]\n",
    "\n",
    "train_metrics_df = metrics_extraction(train_data, column_names_expanded, sortedIndex)\n",
    "test_metrics_df = metrics_extraction(test_data, column_names_expanded, sortedIndex)\n",
    "dataset = pd.concat([train_metrics_df, test_metrics_df], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### iii. Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min1\n",
      "max1\n",
      "mean1\n",
      "median1\n",
      "std1\n",
      "first_quartile1\n",
      "third_quartile1\n",
      "min2\n",
      "max2\n",
      "mean2\n",
      "median2\n",
      "std2\n",
      "first_quartile2\n",
      "third_quartile2\n",
      "min3\n",
      "max3\n",
      "mean3\n",
      "median3\n",
      "std3\n",
      "first_quartile3\n",
      "third_quartile3\n",
      "min4\n",
      "max4\n",
      "mean4\n",
      "median4\n",
      "std4\n",
      "first_quartile4\n",
      "third_quartile4\n",
      "min5\n",
      "max5\n",
      "mean5\n",
      "median5\n",
      "std5\n",
      "first_quartile5\n",
      "third_quartile5\n",
      "min6\n",
      "max6\n",
      "mean6\n",
      "median6\n",
      "std6\n",
      "first_quartile6\n",
      "third_quartile6\n",
      "        min1      max1     mean1   median1      std1  first_quartile1  \\\n",
      "0   8.226156  3.293746  4.651662  4.749431  1.551098         5.521084   \n",
      "1  10.656363  5.204137  5.823893  5.998666  1.938214         6.576368   \n",
      "\n",
      "   third_quartile1  min2      max2     mean2  ...      std5  first_quartile5  \\\n",
      "0         4.243557   0.0  4.647424  1.400281  ...  0.810450         4.726809   \n",
      "1         5.784935   0.0  5.385035  1.697309  ...  1.193208         7.179046   \n",
      "\n",
      "   third_quartile5      min6      max6     mean6   median6      std6  \\\n",
      "0         4.282771  0.000000  2.259877  1.059676  0.988305  0.477494   \n",
      "1         6.441936  0.078029  2.722829  1.208756  1.141127  0.545015   \n",
      "\n",
      "   first_quartile6  third_quartile6  \n",
      "0         0.685538         1.388998  \n",
      "1         0.801363         1.589443  \n",
      "\n",
      "[2 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "empirical_std = dataset.std(axis=0)\n",
    "\n",
    "sample_std = []\n",
    "bootstrap_size = 1000\n",
    "\n",
    "def draw_bs_replicates(data,func,size):\n",
    "    return [func(np.random.choice(data,size=len(data))) for i in range(size) ]\n",
    "\n",
    "\n",
    "bootstrap_df = pd.DataFrame({})\n",
    "ci_df = pd.DataFrame({})\n",
    "for feature in dataset:\n",
    "    bootstrap_df[feature] = draw_bs_replicates(dataset[feature], np.std, bootstrap_size)\n",
    "    \n",
    "idx = 0\n",
    "for feature in bootstrap_df:\n",
    "    conf_interval = np.percentile(bootstrap_df[feature],[5,95])\n",
    "    #print(f\"Empirical Standard Deviation: {empirical_std[idx]}, Bootstrap Standard Deviation: {bootstrap_df[feature].std()}, 90% CI: {conf_interval}\")\n",
    "    ci_df[feature] = conf_interval\n",
    "    idx += 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### iv. Select Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ISLR 3.7.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Linear Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Linear Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Not Linear Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Not Linear Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ISLR 3.7.3 - Extra Practice "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ISLR 3.7.5 - Extra Practice "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294.435px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "3c20c2d94d2527936fe0f3a300eb11db30fed84423423838e2f93b74eb7aaebc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
